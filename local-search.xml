<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>vscode remote SSH + frp</title>
    <link href="/2/"/>
    <url>/2/</url>
    
    <content type="html"><![CDATA[<h3 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h3><p>I heard that vscode remote SSH is now fully available. There has been an idea to configure the laboratory machine for remote programming, but teamviewer is a real card, and other methods are not as good as I want. But the sad thing is that the network architecture of the laboratory is NAT, and I don’t know how many levels of routing have been allocated to my machine. Naturally, my machine does not have a public IP, but I remember that my student discount is 10 yuan. The Alibaba Cloud host is still there every month, and there is a public IP, so let’s start the intranet penetration.</p><p>Update: Personally I feel a little tasteless, because I mainly use python to do more scientific calculations, it is better to use jupyter notebook. . . .</p><h3 id="Materials"><a href="#Materials" class="headerlink" title="Materials"></a>Materials</h3><ol><li>One laboratory machine, system: ubuntu 18.04 desktop 2. One cloud server, system: ubuntu 16.04 server 3. One mac.</li></ol><h3 id="Intranet-penetration"><a href="#Intranet-penetration" class="headerlink" title="Intranet penetration"></a>Intranet penetration</h3><p>The principle of intranet penetration is not introduced. I use <a href="https://github.com/fatedier/frp" target="_blank" rel="noopener">github’s open source project frp</a> . First download frp on two Ubuntu machines respectively</p><pre><code class="hljs sh">$ wget https://github.com/fatedier/frp/releases/download/v0.29.0/frp_0.29.0_freebsd_amd64.tar.gz</code></pre><p>After downloading the compressed package, unzip it, the name is too long, by the way, rename it</p><pre><code class="hljs sh">$ tar -zxvf frp_0.29.0_freebsd_amd64.tar.gz $ mv frp_0.29.0_freebsd_amd64 frp</code></pre><p>Then modify the server’s configuration file</p><pre><code class="hljs sh">$ <span class="hljs-built_in">cd</span> frp $ vi frps.ini</code></pre><p>The content is saved as follows:</p><pre><code class="hljs ini"><span class="hljs-comment"># frps.ini </span><span class="hljs-section">[common]</span> <span class="hljs-attr">bind_port</span> = <span class="hljs-number">7000</span></code></pre><p>Then run the frp server in the background</p><pre><code class="hljs sh">$ nohup ./frps -c ./frps.ini &amp;</code></pre><p>Then modify the configuration of the client (ie the laboratory machine), first enter the location where our client frp is decompressed</p><pre><code class="hljs sh">$ <span class="hljs-built_in">cd</span> frp</code></pre><p>Change setting</p><pre><code class="hljs sh">$ vi frpc.ini is</code></pre><p>The content is saved as follows</p><pre><code class="hljs ini"><span class="hljs-comment"># frpc.ini</span><span class="hljs-section">[common]</span><span class="hljs-attr">server_addr</span> = x.x.x.x<span class="hljs-attr">server_port</span> = <span class="hljs-number">7000</span><span class="hljs-section">[ssh]</span><span class="hljs-attr">type</span> = tcp<span class="hljs-attr">local_ip</span> = <span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span><span class="hljs-attr">local_port</span> = <span class="hljs-number">22</span><span class="hljs-attr">remote_port</span> = <span class="hljs-number">6000</span></code></pre><p>After the above configuration is completed, we need to configure Alibaba Cloud server security group rules to expose ports 7000 and 6000. See how this part of the operation <a href="https://help.aliyun.com/document_detail/25471.html" target="_blank" rel="noopener"> Ali cloud Related Documents </a> Note that the agreement to set up custom tcp, authorization object can be set to <code>0.0.0.0/0</code> server After the port is exposed, you can start the client’s intranet penetration program</p><pre><code class="hljs sh">$ nohup ./frpc -c ./frpc.ini &amp;</code></pre><p>After this operation, you can ssh to the laboratory machine on the mac with the following command</p><pre><code class="hljs sh">$ ssh -oPort=6000 username@server<span class="hljs-string">'s ip</span></code></pre><h3 id="Configure-ssh-password-free-login"><a href="#Configure-ssh-password-free-login" class="headerlink" title="Configure ssh password-free login"></a>Configure ssh password-free login</h3><p>After the above steps are completed, you can ssh to connect to the laboratory machine, but vscode remote ssh requires a public key to log in without password. First generate my public key on mac</p><pre><code class="hljs sh">$ ssh-keygen</code></pre><p>You need to enter some information. If you want to save trouble, just enter the box except the mailbox.</p><pre><code class="hljs sh">$ vi ~/.ssh/id_rsa.pub</code></pre><p>Copy everything inside, this is mac’s public key. Next, I need to find a way to copy the public key to the laboratory machine. I first placed it on the server, connected it to the server with the laboratory machine and then copied it, because the server also added a secret login to my mac.   (however, the security issue of using this public key is your own consideration, I think it is not a big problem)</p><p>Next on the laboratory machine</p><pre><code class="hljs sh">$ vi /etc/ssh/sshd_config</code></pre><p>Make sure to have the following lines</p><pre><code class="hljs ini">RSAAuthentication yesPubkeyAuthentication yesAuthorizedKeysFile  .ssh/authorized_keys</code></pre><p>If it is no, change to yes, if not, add</p><pre><code class="hljs sh">$ vi .ssh/authorized_keys</code></pre><p>Add the public key lab machine just copied from the mac and restart ssh</p><pre><code class="hljs sh">$ service sshd restart</code></pre><p>The following commandssh to the laboratory machine on mac without filling in the password</p><pre><code class="hljs sh">$ ssh -oPort=6000 username@server<span class="hljs-string">'s ip</span></code></pre><h3 id="vscode-remote-ssh-configuration"><a href="#vscode-remote-ssh-configuration" class="headerlink" title="vscode remote ssh configuration"></a>vscode remote ssh configuration</h3><p>After making sure that the mac can log in to the laboratory machine secretly, the next step is very simple, just refer to these two articles <a href="https://code.visualstudio.com/docs/remote/ssh" target="_blank" rel="noopener"> Official Document </a> <a href="https://zhuanlan.zhihu.com/p/64849549" target="_blank" rel="noopener"> 知知上Of </a></p><p>First go to the vscode plugin market to install the plugin:</p><p><img src="1.png" srcset="/img/loading.gif" alt=""></p><p>After installing the plugin, click <code>Add Host</code></p><p><img src="2.png" srcset="/img/loading.gif" alt=""></p><p>Enter host ssh address</p><p><img src="3.png" srcset="/img/loading.gif" alt=""></p><p>Waiting for the connection to complete, we can access the host at home to realize remote development.</p><p><img src="4.png" srcset="/img/loading.gif" alt=""></p><p><img src="5.png" srcset="/img/loading.gif" alt=""></p><h3 id="Experience"><a href="#Experience" class="headerlink" title="Experience"></a>Experience</h3><p>Personally, I feel that the design is very good. If it is only used in a local area network, it should be quite easy to use. However, the use of forced intranet penetration to achieve remote development. First, the bandwidth of the relay server limits the speed of SSH. The second is that I think we have a good rest when we rest, always thinking that remote development is really unnecessary.</p>]]></content>
    
    
    <categories>
      
      <category>Tech Talk</category>
      
    </categories>
    
    
    <tags>
      
      <tag>vscode, frp, ssh</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Duke University&#39;s open source AI algorithm makes mosaic pictures high-definition in seconds</title>
    <link href="/1/"/>
    <url>/1/</url>
    
    <content type="html"><![CDATA[<p>In this era of high-definition image quality, our tolerance for slag image quality is getting lower and lower.</p><p>When you search for “low resolution” and “slag quality” on Zhihu, you will see a large number of problems such as “how to remedy low-resolution photos” and “how to save slag quality”.</p><p>So, what kind of experience is it to change the screen from slag to mosaic level to high definition in seconds? Researchers at Duke University use AI algorithms to tell you.</p><p><img src="1.webp" srcset="/img/loading.gif" alt=""></p><h3 id="Unprecedented-“mosaic”-instantly-becomes-high-definition"><a href="#Unprecedented-“mosaic”-instantly-becomes-high-definition" class="headerlink" title="Unprecedented, “mosaic” instantly becomes high definition"></a>Unprecedented, “mosaic” instantly becomes high definition</h3><p>Researchers at Duke University have proposed an AI algorithm called  PULSE (Photo Upsampling via Latent Space Exploration, photo upsampling through potential space exploration).</p><p>The algorithm can convert blurred, unrecognizable face images into computer-generated images, the details of which are more detailed and realistic than ever before.</p><p><img src="2.gif" srcset="/img/loading.gif" alt=""></p><p>If you use the previous method and want to make a blurred “headshot” clear, you can only zoom this photo up to eight times the original resolution.</p><p>However, the team at Duke University has proposed a new method that can enlarge the 16x16 pixel Low Resolution (hereinafter referred to as LR) thumbnail in 64 seconds to  1024 x in just a few seconds. 1024-pixel high-resolution (High Resolution, HR) image .</p><p>Their AI tools will “imagine” some features that did not exist, even the details that could not be seen in the original LR photos, such as pores, fine lines, eyelashes, hair and stubble, etc., after being processed by their algorithm, they can See clearly.</p><p>Let’s look at a specific example:</p><p><img src="3.webp" srcset="/img/loading.gif" alt=""></p><p>Cynthia Rudin, a computer scientist at Duke University who led the team, said: “It has never been possible to create super-resolution images with a lot of detail using so few pixels like before.”</p><p>In terms of practical applications, Sachit Menon, co-author of the paper, said: “In these studies, we only used the face as a proof of concept.</p><p>But in theory, the technology is universal. From medicine and microscopy to astronomy and satellite imagery, the technology can improve image quality. “</p><h3 id="Break-the-traditional-operation-to-achieve-the-best-results"><a href="#Break-the-traditional-operation-to-achieve-the-best-results" class="headerlink" title="Break the traditional operation to achieve the best results"></a>Break the traditional operation to achieve the best results</h3><p>Although there have been many similar low-definition to high-definition methods before, it is the industry’s first to achieve a pixel magnification of 64 times.</p><blockquote><p>Traditional method: pixel matching, prone to bugs</p></blockquote><p>When dealing with such problems in the traditional way, generally after getting the LR image, you will “guess” how many extra pixels are needed, and then try to match the corresponding pixels in the previously processed HR image to the LR image.</p><p>The result of this simple matching of pixels is that pixels such as hair and skin textures will have mismatched pixels.</p><p>And this method will also ignore the perceptual details such as sensitivity in the HR image. So in the end there will be problems with smoothness and sensitivity, and the result will still look blurry or unreal.</p><p><img src="4.webp" srcset="/img/loading.gif" alt=""></p><blockquote><p>New method: low-definition image “Lianliankan”</p></blockquote><p>The new method proposed by the Duke University team can be said to open up new ideas.</p><p>After getting an LR image, the PULSE system will not slowly add new details, but traverse the HR images generated by the AI, compare the LR images corresponding to these HR images with the original image, and find the closest one.</p><p>An analogy is equivalent to taking the LR picture as a “Lianliankan” to find the most similar LR version, and then pushing it back. The HR image corresponding to this LR image is the final output.</p><p><img src="5.webp" srcset="/img/loading.gif" alt=""></p><p>The team used a generative adversarial network (GAN for short), which includes two neural networks trained on the same photo data set, namely a generator and a discriminator.</p><p>Among them, the generator simulates the face it has been trained to provide the face created by AI, and the discriminator obtains the output and determines whether it is enough to be fake.</p><p>With the accumulation of experience, the experience of the generator will get better and better until the discriminator cannot distinguish the difference.</p><p>They experimented with some real images, and the effect comparison is shown below:</p><p><img src="6.webp" srcset="/img/loading.gif" alt=""></p><p>Although there is still some gap between the generated high-resolution image and the original image, it is much clearer than the previous method.</p><h3 id="Evaluation-better-than-other-methods-score-close-to-real-photos"><a href="#Evaluation-better-than-other-methods-score-close-to-real-photos" class="headerlink" title="Evaluation: better than other methods, score close to real photos"></a>Evaluation: better than other methods, score close to real photos</h3><p>The team evaluated its algorithm on the famous high-resolution face dataset CelebA HQ, and conducted these experiments with scale factors of 64×, 32×, and 8×.</p><p>The researchers asked 40 people to rate 1,440 images generated by PULSE and five other zoom methods, with PULSE performing best, with scores almost as high as real high-quality photos.</p><p><img src="6.webp" srcset="/img/loading.gif" alt=""></p><p>Team members said that PULSE can create realistic images from noisy, low-quality input, even if the original image is not recognizable by eyes or mouth. This cannot be done by other methods.</p><p><img src="7.webp" srcset="/img/loading.gif" alt=""></p><p>However, the system cannot yet be used to identify identities, the researchers said: “It cannot turn out-of-focus, unrecognizable photos taken by a security camera into a clear image of a real person. It will only generate non-existent but seemingly real New face.”</p><p>In specific application scenarios, in addition to the above mentioned, the technology may be used in medicine and astronomy in the future. For the public, after having this black technology, you can change the old photos of N years ago to high definition. For editors and comrades, this is a great gospel, and you don’t have to look for high-resolution pictures anymore.</p><p>Reminder: The researchers will also introduce their methods at the ongoing CVPR 2020 (Computer Vision and Pattern Recognition Conference), you can pay attention to:</p><ul><li><p><a href="http://cvpr2020.thecvf.com/program/tutorials" target="_blank" rel="noopener">http://cvpr2020.thecvf.com/program/tutorials</a></p></li><li><p>Thesis address:<br><a href="https://arxiv.org/pdf/2003.03808.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/2003.03808.pdf</a></p></li><li><p>Reference materials:<br><a href="https://www.sciencedaily.com/releases/2020/06/200612111409.htm" target="_blank" rel="noopener">https://www.sciencedaily.com/releases/2020/06/200612111409.htm</a></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Tech Talk</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI, Computer vision</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
